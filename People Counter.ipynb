{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iCKVoor4h-cb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-6B4hKLiJbA",
        "outputId": "2024fa07-88b3-4800-e0e9-fd71d8ba48d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.228)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbmqCsn2iLSL",
        "outputId": "8402830a-30c4-4d4c-e003-81c3d0047147"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "n6pSQ7tYiRD4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cvzone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL4lrqEyinO2",
        "outputId": "627a8d42-c335-427d-9cca-2447d34339b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cvzone in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from cvzone) (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cvzone) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cvzone"
      ],
      "metadata": {
        "id": "D6YLykmuisCJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8m-seg.pt\")"
      ],
      "metadata": {
        "id": "JC-RaJoUi4vW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = cv2.VideoWriter('/content/output.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 15, (1280,720))\n",
        "cap = cv2.VideoCapture('/content/People-walking.mp4')\n",
        "\n",
        "while True:\n",
        "    ret,frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "\n",
        "    results = model.predict(frame)\n",
        "    segmented_frame = results[0].plot()\n",
        "\n",
        "    countlist = []\n",
        "\n",
        "    for result in results:\n",
        "      boxes = result.boxes.cpu().numpy()\n",
        "      boxes_data = boxes.data\n",
        "      box_xyxys = boxes.xyxy\n",
        "      box_classes = boxes.cls\n",
        "      seg = result.masks.xy\n",
        "\n",
        "      for xyxy in box_xyxys:\n",
        "        cv2.rectangle(frame, (int(xyxy[0]),int(xyxy[1])) ,(int(xyxy[2]),int(xyxy[3])), (0,0,255),1)\n",
        "\n",
        "      for xy in seg:\n",
        "        xy = np.int32([xy])\n",
        "        cv2.polylines(frame, xy, True, (0,0,255), 4)\n",
        "\n",
        "      for cls in box_classes:\n",
        "        if int(cls) == 0:\n",
        "          countlist.append(int(cls))\n",
        "\n",
        "    counted = len(countlist)\n",
        "\n",
        "    cvzone.putTextRect(frame, f'People count: {counted}', (50,60), 3, 1,colorR=(255, 0, 0))\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "    if cv2.waitKey(1)&0xFF==27:\n",
        "        break\n",
        "\n",
        "\n",
        "out.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exwej5JVkj40",
        "outputId": "85647c4f-7766-432d-c964-c6f2bba3bd70"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 30 persons, 31.1ms\n",
            "Speed: 2.4ms preprocess, 31.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 33.2ms\n",
            "Speed: 7.0ms preprocess, 33.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 31.2ms\n",
            "Speed: 2.2ms preprocess, 31.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 31.0ms\n",
            "Speed: 2.1ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 31.1ms\n",
            "Speed: 1.6ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 clock, 31.6ms\n",
            "Speed: 2.7ms preprocess, 31.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 1 clock, 30.3ms\n",
            "Speed: 2.0ms preprocess, 30.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 1 clock, 28.4ms\n",
            "Speed: 2.1ms preprocess, 28.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 28.6ms\n",
            "Speed: 2.0ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 27.0ms\n",
            "Speed: 2.9ms preprocess, 27.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 27.0ms\n",
            "Speed: 1.9ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 1 clock, 27.0ms\n",
            "Speed: 1.8ms preprocess, 27.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 1 clock, 27.1ms\n",
            "Speed: 2.0ms preprocess, 27.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 1 clock, 27.0ms\n",
            "Speed: 1.9ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 1 clock, 27.2ms\n",
            "Speed: 2.1ms preprocess, 27.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 1 clock, 27.0ms\n",
            "Speed: 1.8ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 1 clock, 27.0ms\n",
            "Speed: 1.9ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 1 clock, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 handbag, 25.9ms\n",
            "Speed: 7.5ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 handbag, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 28.1ms\n",
            "Speed: 2.0ms preprocess, 28.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 25.9ms\n",
            "Speed: 4.1ms preprocess, 25.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 25.9ms\n",
            "Speed: 1.6ms preprocess, 25.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 handbag, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 handbag, 26.7ms\n",
            "Speed: 2.1ms preprocess, 26.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 handbag, 1 skateboard, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 backpack, 1 handbag, 1 skateboard, 24.6ms\n",
            "Speed: 2.0ms preprocess, 24.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 handbag, 24.6ms\n",
            "Speed: 3.5ms preprocess, 24.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 25.2ms\n",
            "Speed: 2.2ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 24.9ms\n",
            "Speed: 1.9ms preprocess, 24.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 24.6ms\n",
            "Speed: 2.0ms preprocess, 24.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 24.6ms\n",
            "Speed: 2.0ms preprocess, 24.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 handbags, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 25.6ms\n",
            "Speed: 2.0ms preprocess, 25.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 24.7ms\n",
            "Speed: 1.9ms preprocess, 24.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 25.0ms\n",
            "Speed: 2.3ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 24.8ms\n",
            "Speed: 3.2ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 24.2ms\n",
            "Speed: 1.9ms preprocess, 24.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 handbag, 24.2ms\n",
            "Speed: 2.0ms preprocess, 24.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 24.8ms\n",
            "Speed: 2.1ms preprocess, 24.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 25.0ms\n",
            "Speed: 2.2ms preprocess, 25.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 24.5ms\n",
            "Speed: 2.0ms preprocess, 24.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 24.2ms\n",
            "Speed: 2.0ms preprocess, 24.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 24.3ms\n",
            "Speed: 2.0ms preprocess, 24.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 1 clock, 24.4ms\n",
            "Speed: 1.9ms preprocess, 24.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 1 handbag, 1 clock, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 24.2ms\n",
            "Speed: 1.9ms preprocess, 24.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 24.2ms\n",
            "Speed: 2.1ms preprocess, 24.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 24.4ms\n",
            "Speed: 1.8ms preprocess, 24.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 24.7ms\n",
            "Speed: 1.8ms preprocess, 24.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 24.2ms\n",
            "Speed: 1.7ms preprocess, 24.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 25.5ms\n",
            "Speed: 1.8ms preprocess, 25.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 24.2ms\n",
            "Speed: 2.2ms preprocess, 24.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 1 skis, 29.7ms\n",
            "Speed: 4.3ms preprocess, 29.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 1 skis, 31.1ms\n",
            "Speed: 2.1ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 1 skis, 31.5ms\n",
            "Speed: 2.0ms preprocess, 31.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 1 skis, 31.0ms\n",
            "Speed: 4.6ms preprocess, 31.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 1 skis, 31.1ms\n",
            "Speed: 2.2ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 31.1ms\n",
            "Speed: 2.2ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 31.1ms\n",
            "Speed: 2.1ms preprocess, 31.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 handbag, 31.1ms\n",
            "Speed: 1.9ms preprocess, 31.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 31.3ms\n",
            "Speed: 2.2ms preprocess, 31.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 31.1ms\n",
            "Speed: 1.9ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 33.4ms\n",
            "Speed: 2.2ms preprocess, 33.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 31.1ms\n",
            "Speed: 4.1ms preprocess, 31.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 handbags, 31.1ms\n",
            "Speed: 1.9ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 31.6ms\n",
            "Speed: 2.1ms preprocess, 31.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 31.1ms\n",
            "Speed: 2.0ms preprocess, 31.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 handbag, 31.5ms\n",
            "Speed: 2.0ms preprocess, 31.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 handbag, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 1 handbag, 31.4ms\n",
            "Speed: 2.6ms preprocess, 31.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 31.1ms\n",
            "Speed: 2.0ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 1 tennis racket, 31.1ms\n",
            "Speed: 4.2ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 1 tennis racket, 31.0ms\n",
            "Speed: 2.3ms preprocess, 31.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 1 tennis racket, 31.1ms\n",
            "Speed: 6.5ms preprocess, 31.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 31.3ms\n",
            "Speed: 2.2ms preprocess, 31.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 31.0ms\n",
            "Speed: 1.9ms preprocess, 31.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 31.1ms\n",
            "Speed: 2.1ms preprocess, 31.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 31.0ms\n",
            "Speed: 2.2ms preprocess, 31.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 31.2ms\n",
            "Speed: 1.9ms preprocess, 31.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 handbag, 31.3ms\n",
            "Speed: 2.0ms preprocess, 31.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 28.1ms\n",
            "Speed: 2.3ms preprocess, 28.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 handbags, 28.2ms\n",
            "Speed: 2.2ms preprocess, 28.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 3 handbags, 28.0ms\n",
            "Speed: 2.4ms preprocess, 28.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 27.9ms\n",
            "Speed: 2.2ms preprocess, 27.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 3 handbags, 27.9ms\n",
            "Speed: 5.0ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 3 handbags, 27.9ms\n",
            "Speed: 1.9ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 27.9ms\n",
            "Speed: 1.9ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 28.0ms\n",
            "Speed: 3.9ms preprocess, 28.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 28.0ms\n",
            "Speed: 2.5ms preprocess, 28.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 handbag, 27.9ms\n",
            "Speed: 2.0ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 27.9ms\n",
            "Speed: 2.2ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 27.9ms\n",
            "Speed: 2.3ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 27.8ms\n",
            "Speed: 1.7ms preprocess, 27.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 2 handbags, 27.9ms\n",
            "Speed: 4.1ms preprocess, 27.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 28.0ms\n",
            "Speed: 5.2ms preprocess, 28.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 29.7ms\n",
            "Speed: 1.9ms preprocess, 29.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 27.9ms\n",
            "Speed: 2.0ms preprocess, 27.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 27.9ms\n",
            "Speed: 2.1ms preprocess, 27.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 31.1ms\n",
            "Speed: 2.0ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 30.5ms\n",
            "Speed: 1.9ms preprocess, 30.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 28.7ms\n",
            "Speed: 1.9ms preprocess, 28.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 27.9ms\n",
            "Speed: 2.2ms preprocess, 27.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 2 handbags, 27.9ms\n",
            "Speed: 2.0ms preprocess, 27.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 handbags, 27.0ms\n",
            "Speed: 2.0ms preprocess, 27.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 1 clock, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 26.9ms\n",
            "Speed: 5.7ms preprocess, 26.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 1 handbag, 27.0ms\n",
            "Speed: 2.1ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 1 backpack, 1 handbag, 27.0ms\n",
            "Speed: 2.1ms preprocess, 27.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 1 tennis racket, 27.0ms\n",
            "Speed: 1.9ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 1 tennis racket, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 1 tennis racket, 26.8ms\n",
            "Speed: 2.1ms preprocess, 26.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 26.9ms\n",
            "Speed: 2.2ms preprocess, 26.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 handbags, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 27.1ms\n",
            "Speed: 1.8ms preprocess, 27.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 handbags, 29.1ms\n",
            "Speed: 1.9ms preprocess, 29.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 26.7ms\n",
            "Speed: 2.0ms preprocess, 26.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 handbag, 1 tennis racket, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 tennis racket, 25.4ms\n",
            "Speed: 2.0ms preprocess, 25.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 tennis racket, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 25.6ms\n",
            "Speed: 1.9ms preprocess, 25.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 1 tennis racket, 25.5ms\n",
            "Speed: 1.8ms preprocess, 25.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 clock, 25.5ms\n",
            "Speed: 3.4ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 1 clock, 25.6ms\n",
            "Speed: 3.4ms preprocess, 25.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 1 clock, 25.4ms\n",
            "Speed: 2.4ms preprocess, 25.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 1 clock, 25.6ms\n",
            "Speed: 2.0ms preprocess, 25.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 5 handbags, 25.5ms\n",
            "Speed: 4.0ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 25.7ms\n",
            "Speed: 2.0ms preprocess, 25.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 4 handbags, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 25.6ms\n",
            "Speed: 2.3ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 25.4ms\n",
            "Speed: 2.3ms preprocess, 25.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 25.5ms\n",
            "Speed: 2.1ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 25.5ms\n",
            "Speed: 3.3ms preprocess, 25.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 handbag, 23.8ms\n",
            "Speed: 1.8ms preprocess, 23.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 handbag, 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 handbag, 23.8ms\n",
            "Speed: 1.7ms preprocess, 23.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 23.9ms\n",
            "Speed: 2.1ms preprocess, 23.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 25.4ms\n",
            "Speed: 2.5ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 25.2ms\n",
            "Speed: 2.2ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 23.9ms\n",
            "Speed: 2.3ms preprocess, 23.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 23.8ms\n",
            "Speed: 1.8ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 23.8ms\n",
            "Speed: 1.8ms preprocess, 23.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 backpack, 3 handbags, 23.5ms\n",
            "Speed: 2.0ms preprocess, 23.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 23.9ms\n",
            "Speed: 2.5ms preprocess, 23.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 23.6ms\n",
            "Speed: 2.0ms preprocess, 23.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 23.7ms\n",
            "Speed: 2.1ms preprocess, 23.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 23.9ms\n",
            "Speed: 2.0ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 23.5ms\n",
            "Speed: 2.5ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 23.5ms\n",
            "Speed: 2.1ms preprocess, 23.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 5 handbags, 23.5ms\n",
            "Speed: 3.0ms preprocess, 23.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 23.5ms\n",
            "Speed: 4.7ms preprocess, 23.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 1 suitcase, 24.0ms\n",
            "Speed: 2.0ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 1 suitcase, 23.5ms\n",
            "Speed: 1.9ms preprocess, 23.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 handbag, 1 suitcase, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 22.8ms\n",
            "Speed: 1.7ms preprocess, 22.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 2 handbags, 22.6ms\n",
            "Speed: 2.5ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 22.6ms\n",
            "Speed: 1.9ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 22.6ms\n",
            "Speed: 2.1ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 1 handbag, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 23.0ms\n",
            "Speed: 2.4ms preprocess, 23.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 22.6ms\n",
            "Speed: 2.4ms preprocess, 22.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 22.6ms\n",
            "Speed: 2.5ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 1 skis, 25.3ms\n",
            "Speed: 2.0ms preprocess, 25.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 22.7ms\n",
            "Speed: 2.2ms preprocess, 22.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 22.6ms\n",
            "Speed: 1.9ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 23.4ms\n",
            "Speed: 1.9ms preprocess, 23.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 handbags, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 22.6ms\n",
            "Speed: 1.8ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 22.6ms\n",
            "Speed: 1.9ms preprocess, 22.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 23.5ms\n",
            "Speed: 1.9ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 22.6ms\n",
            "Speed: 2.1ms preprocess, 22.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 22.9ms\n",
            "Speed: 2.2ms preprocess, 22.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 22.6ms\n",
            "Speed: 2.5ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 22.8ms\n",
            "Speed: 2.1ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 handbags, 22.6ms\n",
            "Speed: 2.2ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 4 handbags, 22.7ms\n",
            "Speed: 2.0ms preprocess, 22.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 3 handbags, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 4 handbags, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 22.6ms\n",
            "Speed: 1.9ms preprocess, 22.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 22.7ms\n",
            "Speed: 3.8ms preprocess, 22.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 24.6ms\n",
            "Speed: 2.0ms preprocess, 24.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 1 handbag, 22.7ms\n",
            "Speed: 2.7ms preprocess, 22.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 22.7ms\n",
            "Speed: 2.1ms preprocess, 22.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 23.7ms\n",
            "Speed: 2.0ms preprocess, 23.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 22.7ms\n",
            "Speed: 1.9ms preprocess, 22.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 25.4ms\n",
            "Speed: 2.0ms preprocess, 25.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 26.9ms\n",
            "Speed: 1.8ms preprocess, 26.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 27.4ms\n",
            "Speed: 2.0ms preprocess, 27.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 27.5ms\n",
            "Speed: 2.0ms preprocess, 27.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 28.0ms\n",
            "Speed: 2.1ms preprocess, 28.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 28.0ms\n",
            "Speed: 2.2ms preprocess, 28.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 28.6ms\n",
            "Speed: 2.1ms preprocess, 28.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 30.6ms\n",
            "Speed: 2.0ms preprocess, 30.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 29.1ms\n",
            "Speed: 2.0ms preprocess, 29.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 29.8ms\n",
            "Speed: 2.0ms preprocess, 29.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 30.0ms\n",
            "Speed: 2.1ms preprocess, 30.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 30.5ms\n",
            "Speed: 2.2ms preprocess, 30.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 34.8ms\n",
            "Speed: 1.9ms preprocess, 34.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 31.0ms\n",
            "Speed: 1.9ms preprocess, 31.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 31.1ms\n",
            "Speed: 1.9ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 31.1ms\n",
            "Speed: 1.9ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 31.5ms\n",
            "Speed: 2.0ms preprocess, 31.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 31.1ms\n",
            "Speed: 2.1ms preprocess, 31.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 31.2ms\n",
            "Speed: 2.0ms preprocess, 31.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 4 handbags, 31.1ms\n",
            "Speed: 2.0ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 4 handbags, 31.1ms\n",
            "Speed: 3.7ms preprocess, 31.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 32.1ms\n",
            "Speed: 1.8ms preprocess, 32.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 31.5ms\n",
            "Speed: 2.0ms preprocess, 31.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 4 handbags, 32.3ms\n",
            "Speed: 1.9ms preprocess, 32.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 4 handbags, 31.4ms\n",
            "Speed: 1.9ms preprocess, 31.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 31.1ms\n",
            "Speed: 2.2ms preprocess, 31.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 31.0ms\n",
            "Speed: 2.3ms preprocess, 31.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 4 handbags, 31.1ms\n",
            "Speed: 2.2ms preprocess, 31.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 3 handbags, 31.1ms\n",
            "Speed: 6.1ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 31.1ms\n",
            "Speed: 8.0ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 31.0ms\n",
            "Speed: 3.6ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 31.1ms\n",
            "Speed: 2.1ms preprocess, 31.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 31.6ms\n",
            "Speed: 2.0ms preprocess, 31.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 2 handbags, 31.4ms\n",
            "Speed: 2.2ms preprocess, 31.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 4 handbags, 31.4ms\n",
            "Speed: 2.1ms preprocess, 31.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 31.1ms\n",
            "Speed: 2.3ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 handbags, 31.1ms\n",
            "Speed: 2.2ms preprocess, 31.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 3 handbags, 31.0ms\n",
            "Speed: 1.8ms preprocess, 31.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 1 backpack, 3 handbags, 31.2ms\n",
            "Speed: 1.9ms preprocess, 31.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 29.9ms\n",
            "Speed: 1.9ms preprocess, 29.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 28.6ms\n",
            "Speed: 2.0ms preprocess, 28.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 28.7ms\n",
            "Speed: 2.1ms preprocess, 28.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 5 handbags, 26.5ms\n",
            "Speed: 1.7ms preprocess, 26.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 handbags, 26.4ms\n",
            "Speed: 2.0ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 4 handbags, 26.4ms\n",
            "Speed: 2.1ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 5 handbags, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 6 handbags, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 6 handbags, 26.4ms\n",
            "Speed: 2.0ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 6 handbags, 26.8ms\n",
            "Speed: 2.0ms preprocess, 26.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 1 backpack, 4 handbags, 26.4ms\n",
            "Speed: 2.5ms preprocess, 26.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 4 handbags, 26.4ms\n",
            "Speed: 1.9ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 1 tennis racket, 26.4ms\n",
            "Speed: 2.0ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 2 handbags, 27.3ms\n",
            "Speed: 3.9ms preprocess, 27.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 backpacks, 3 handbags, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 27.9ms\n",
            "Speed: 2.1ms preprocess, 27.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 handbags, 26.5ms\n",
            "Speed: 2.2ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 26.6ms\n",
            "Speed: 2.1ms preprocess, 26.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 3 handbags, 26.5ms\n",
            "Speed: 2.1ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 26.6ms\n",
            "Speed: 1.8ms preprocess, 26.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 26.7ms\n",
            "Speed: 2.0ms preprocess, 26.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 29.0ms\n",
            "Speed: 2.0ms preprocess, 29.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 29.1ms\n",
            "Speed: 1.9ms preprocess, 29.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 handbags, 76.9ms\n",
            "Speed: 2.4ms preprocess, 76.9ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 5 handbags, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 31.0ms\n",
            "Speed: 2.8ms preprocess, 31.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 4 handbags, 31.7ms\n",
            "Speed: 2.7ms preprocess, 31.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 5 handbags, 31.3ms\n",
            "Speed: 2.8ms preprocess, 31.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 5 handbags, 31.3ms\n",
            "Speed: 2.2ms preprocess, 31.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 4 handbags, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 31.0ms\n",
            "Speed: 1.7ms preprocess, 31.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 4 handbags, 31.0ms\n",
            "Speed: 2.1ms preprocess, 31.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 31.0ms\n",
            "Speed: 2.4ms preprocess, 31.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 2 handbags, 31.0ms\n",
            "Speed: 2.0ms preprocess, 31.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 31.3ms\n",
            "Speed: 2.1ms preprocess, 31.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 31.1ms\n",
            "Speed: 2.3ms preprocess, 31.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 31.6ms\n",
            "Speed: 2.0ms preprocess, 31.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 30.6ms\n",
            "Speed: 2.0ms preprocess, 30.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 30.6ms\n",
            "Speed: 2.0ms preprocess, 30.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 29.6ms\n",
            "Speed: 2.0ms preprocess, 29.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 27.4ms\n",
            "Speed: 1.9ms preprocess, 27.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 27.8ms\n",
            "Speed: 2.0ms preprocess, 27.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 26.7ms\n",
            "Speed: 2.0ms preprocess, 26.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 handbag, 32.2ms\n",
            "Speed: 2.0ms preprocess, 32.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 26.4ms\n",
            "Speed: 1.9ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 3 handbags, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 dog, 3 handbags, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 dog, 2 handbags, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 26.4ms\n",
            "Speed: 2.4ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 backpack, 2 handbags, 26.8ms\n",
            "Speed: 2.0ms preprocess, 26.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 backpack, 3 handbags, 26.7ms\n",
            "Speed: 2.6ms preprocess, 26.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 dog, 2 handbags, 26.4ms\n",
            "Speed: 1.9ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 handbag, 26.5ms\n",
            "Speed: 1.9ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 3 handbags, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 1 backpack, 2 handbags, 25.7ms\n",
            "Speed: 2.3ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 25.5ms\n",
            "Speed: 1.9ms preprocess, 25.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 3 handbags, 25.5ms\n",
            "Speed: 1.8ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 25.5ms\n",
            "Speed: 1.8ms preprocess, 25.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 2 handbags, 1 skis, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 26.0ms\n",
            "Speed: 4.3ms preprocess, 26.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 25.4ms\n",
            "Speed: 2.1ms preprocess, 25.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 3 handbags, 25.6ms\n",
            "Speed: 4.6ms preprocess, 25.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 3 handbags, 25.7ms\n",
            "Speed: 2.3ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 3 handbags, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 3 handbags, 1 clock, 25.1ms\n",
            "Speed: 2.1ms preprocess, 25.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 backpack, 3 handbags, 1 clock, 25.0ms\n",
            "Speed: 1.9ms preprocess, 25.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 1 backpack, 2 handbags, 1 clock, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 1 clock, 25.0ms\n",
            "Speed: 2.0ms preprocess, 25.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 1 clock, 25.1ms\n",
            "Speed: 2.1ms preprocess, 25.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 handbag, 1 clock, 25.1ms\n",
            "Speed: 2.6ms preprocess, 25.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 25.0ms\n",
            "Speed: 1.9ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 1 umbrella, 2 handbags, 25.1ms\n",
            "Speed: 1.9ms preprocess, 25.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 26.4ms\n",
            "Speed: 2.0ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 1 umbrella, 2 handbags, 25.2ms\n",
            "Speed: 2.0ms preprocess, 25.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 2 handbags, 1 clock, 25.3ms\n",
            "Speed: 1.9ms preprocess, 25.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 1 clock, 25.2ms\n",
            "Speed: 2.4ms preprocess, 25.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 25.0ms\n",
            "Speed: 2.3ms preprocess, 25.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 2 handbags, 25.1ms\n",
            "Speed: 2.0ms preprocess, 25.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 2 handbags, 25.0ms\n",
            "Speed: 2.1ms preprocess, 25.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 25.2ms\n",
            "Speed: 2.4ms preprocess, 25.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 umbrella, 3 handbags, 25.2ms\n",
            "Speed: 2.2ms preprocess, 25.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 1 umbrella, 2 handbags, 25.3ms\n",
            "Speed: 1.9ms preprocess, 25.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 umbrella, 3 handbags, 25.1ms\n",
            "Speed: 2.0ms preprocess, 25.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 1 umbrella, 3 handbags, 27.1ms\n",
            "Speed: 3.2ms preprocess, 27.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 3 handbags, 27.1ms\n",
            "Speed: 2.6ms preprocess, 27.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 2 handbags, 27.0ms\n",
            "Speed: 3.1ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 2 handbags, 26.9ms\n",
            "Speed: 2.3ms preprocess, 26.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    }
  ]
}